{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5KTrLJKD-l7",
        "colab_type": "text"
      },
      "source": [
        "# Homework 4: Neural Sequence Labeling\n",
        "\n",
        "**Due March 4, 2020 at 11:59PM**\n",
        "\n",
        "\n",
        "In this homework, you will be implementing, training, and evaluating an LSTM for part-of-speech tagging using the PyTorch library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFgEH9BWEqPV",
        "colab_type": "text"
      },
      "source": [
        "**Before beginning, please switch your Colab session to a GPU runtime** \n",
        "\n",
        "Go to Runtime > Change runtime type > Hardware accelerator > GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xALTxzWIEkkE",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk8GRWIkbrU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t87Vex5_b5MI",
        "colab_type": "code",
        "outputId": "de3c6bbf-8f65-4fff-a68f-3c3c02d0dd3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# if this cell prints \"Running on cpu\", you must switch runtime environments\n",
        "# go to Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on {}\".format(device))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3nDS9MwFCVf",
        "colab_type": "text"
      },
      "source": [
        "### Download & Load Pretrained Embeddings\n",
        "\n",
        "In this assignment, we will be using GloVe pretrained word embeddings. You can read more about GloVe here: https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "**Note**: this section will take *several minutes*, since the embedding files are large. Files in Colab may be cached between sessions, so you may or may not need to redownload the files each time you reconnect. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csWld6ckFNL1",
        "colab_type": "code",
        "outputId": "c2e3fa76-f011-4a45-d54a-93904b0ea47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# download pretrained word embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-06 07:20:27--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-03-06 07:20:28--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-03-06 07:20:28--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  2.18MB/s    in 6m 29s  \n",
            "\n",
            "2020-03-06 07:26:58 (2.11 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.100d.txt       \n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.200d.txt       \n",
            "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiuJ5eylL0A0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_embeddings(filename, vocab_size=10000):\n",
        "  \"\"\"\n",
        "  Utility function, loads in the `vocab_size` most common embeddings from `filename`\n",
        "  \n",
        "  Arguments:\n",
        "  - filename:     path to file\n",
        "                  automatically infers correct embedding dimension from filename\n",
        "  - vocab_size:   maximum number of embeddings to load\n",
        "\n",
        "  Returns \n",
        "  - embeddings:   torch.FloatTensor matrix of size (vocab_size x word_embedding_dim)\n",
        "  - vocab:        dictionary mapping word (str) to index (int) in embedding matrix\n",
        "  \"\"\"\n",
        "\n",
        "  # get the embedding size from the first embedding\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    word_embedding_dim = len(file.readline().split(\" \")) - 1\n",
        "\n",
        "  vocab = {}\n",
        "\n",
        "  embeddings = np.zeros((vocab_size, word_embedding_dim))\n",
        "\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    for idx, line in enumerate(file):\n",
        "\n",
        "      if idx + 2 >= vocab_size:\n",
        "        break\n",
        "\n",
        "      cols = line.rstrip().split(\" \")\n",
        "      val = np.array(cols[1:])\n",
        "      word = cols[0]\n",
        "      embeddings[idx + 2] = val\n",
        "      vocab[word] = idx + 2\n",
        "  \n",
        "  # a FloatTensor is a multidimensional matrix\n",
        "  # that contains 32-bit floats in every entry\n",
        "  # https://pytorch.org/docs/stable/tensors.html\n",
        "  return torch.FloatTensor(embeddings), vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ah3clY7lHNZ",
        "colab_type": "text"
      },
      "source": [
        "Running the cell below lists all the files in the current directory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D__oK6mQ6hs",
        "colab_type": "code",
        "outputId": "de03b11e-a465-4de2-f2c3-b4143b4ed0cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "!ls -lh"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 3.8G\n",
            "-rw-rw-r-- 1 root root 332M Aug  4  2014 glove.6B.100d.txt\n",
            "-rw-rw-r-- 1 root root 662M Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r-- 1 root root 990M Aug 27  2014 glove.6B.300d.txt\n",
            "-rw-rw-r-- 1 root root 164M Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-r--r-- 1 root root 823M Oct 25  2015 glove.6B.zip\n",
            "-rw-r--r-- 1 root root 823M Oct 25  2015 glove.6B.zip.1\n",
            "-rw-r--r-- 1 root root 209K Mar  6 05:50 pos.dev\n",
            "-rw-r--r-- 1 root root 209K Mar  6 05:52 pos.dev.1\n",
            "-rw-r--r-- 1 root root 209K Mar  6 06:38 pos.dev.2\n",
            "-rw-r--r-- 1 root root 209K Mar  6 06:41 pos.dev.3\n",
            "-rw-r--r-- 1 root root 209K Mar  6 07:14 pos.dev.4\n",
            "-rw-r--r-- 1 root root 209K Mar  6 07:19 pos.dev.5\n",
            "-rw-r--r-- 1 root root  319 Mar  6 05:50 pos.tagset\n",
            "-rw-r--r-- 1 root root  319 Mar  6 05:52 pos.tagset.1\n",
            "-rw-r--r-- 1 root root  319 Mar  6 06:38 pos.tagset.2\n",
            "-rw-r--r-- 1 root root  319 Mar  6 06:41 pos.tagset.3\n",
            "-rw-r--r-- 1 root root  319 Mar  6 07:14 pos.tagset.4\n",
            "-rw-r--r-- 1 root root  319 Mar  6 07:19 pos.tagset.5\n",
            "-rw-r--r-- 1 root root 128K Mar  6 05:50 pos.test\n",
            "-rw-r--r-- 1 root root 128K Mar  6 05:52 pos.test.1\n",
            "-rw-r--r-- 1 root root 128K Mar  6 06:38 pos.test.2\n",
            "-rw-r--r-- 1 root root 128K Mar  6 06:41 pos.test.3\n",
            "-rw-r--r-- 1 root root 128K Mar  6 07:14 pos.test.4\n",
            "-rw-r--r-- 1 root root 128K Mar  6 07:19 pos.test.5\n",
            "-rw-r--r-- 1 root root 1.7M Mar  6 05:50 pos.train\n",
            "-rw-r--r-- 1 root root 1.7M Mar  6 05:52 pos.train.1\n",
            "-rw-r--r-- 1 root root 1.7M Mar  6 06:38 pos.train.2\n",
            "-rw-r--r-- 1 root root 1.7M Mar  6 06:41 pos.train.3\n",
            "-rw-r--r-- 1 root root 1.7M Mar  6 07:14 pos.train.4\n",
            "-rw-r--r-- 1 root root 1.7M Mar  6 07:19 pos.train.5\n",
            "-rw-r--r-- 1 root root  70K Mar  6 06:33 predictions.txt\n",
            "drwxr-xr-x 1 root root 4.0K Mar  3 18:11 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoSWrCwZllg6",
        "colab_type": "text"
      },
      "source": [
        "You should see several embedding files, which are all formatted as\n",
        "\n",
        "```\n",
        "glove.6B.<emb_dim>d.txt\n",
        "```\n",
        "\n",
        "Each `txt` file contains `emb_dim` dimensional embeddings for 400,000 unique, uncased words. The script below loads the `vocab_size` most common words from the embedding file into a matrix we can give to our model. All other words will later be mapped to the `UNKNOWN` embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL8WuEZoOFbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this loads the 10,000 most common word 50-dimensional embeddings\n",
        "vocab_size = 10000\n",
        "embeddings, vocab = read_embeddings('glove.6B.50d.txt', vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py9AStUOJnPB",
        "colab_type": "text"
      },
      "source": [
        "## Part 1: Batching the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5jWl-z8w_5t",
        "colab_type": "text"
      },
      "source": [
        "Implement the `get_batches` function in the `Dataset` class below. \n",
        "\n",
        "**Please make sure that**\n",
        "\n",
        "*   Your implementation is self-contained. That is, all helper functions and variables are defined within `get_batches`.\n",
        "*   Your implementation can handle variable batch sizes. You may not assume that the value with always be 32\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KWyqb2HcLop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset():\n",
        "  def __init__(self, filename, is_labeled):\n",
        "    self.is_labeled = is_labeled\n",
        "    # if the file is not labeled, the Dataset has no tags (see read_data)\n",
        "    if is_labeled:\n",
        "      self.sentences, self.tags = self.read_data(filename, is_labeled)\n",
        "    else:\n",
        "      self.sentences = self.read_data(filename, is_labeled)\n",
        "      self.tags = None\n",
        "\n",
        "  def read_data(self, filename, is_labeled):\n",
        "    \"\"\"\n",
        "    Utility function, loads text file into a list of sentence and tag strings\n",
        "\n",
        "    Arguments:\n",
        "    - filename:     path to file\n",
        "    - is_labeled:   whether the file contains tags for each word or not\n",
        "        > if True, we assume each line is formatted as \"<word>\\t<tag>\\n\"\n",
        "        > if False, we assume each line is formatted as \"<word>\\n\"\n",
        "\n",
        "    Returns:\n",
        "    - sentences:    a list of sentences, where each sentence is a list \n",
        "                    words (strings)\n",
        "\n",
        "    if is_labeled=True, also returns\n",
        "    - tags:         a list of tags for each sentence, where tags[i] contains\n",
        "                    a list of tags (strings) that correspond to the words in \n",
        "                    sentences[i]\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    tags = []\n",
        "\n",
        "    current_sentence = []\n",
        "    current_tags = []\n",
        "\n",
        "    with open(filename, encoding='utf8') as f:\n",
        "      # iterate over the lines in the file\n",
        "      for line in f:\n",
        "        if len(line) == 0:\n",
        "          continue\n",
        "        if line == '\\n':\n",
        "          if len(current_sentence) != 0:\n",
        "            sentences.append(current_sentence)\n",
        "            tags.append(current_tags)\n",
        "\n",
        "          current_sentence = []\n",
        "          current_tags = []\n",
        "        else:\n",
        "          if is_labeled:\n",
        "            columns = line.rstrip().split('\\t')\n",
        "            word = columns[0].lower()\n",
        "            tag = columns[1]\n",
        "\n",
        "            current_sentence.append(word)\n",
        "            current_tags.append(tag)\n",
        "          else:\n",
        "            column = line.rstrip().split('\\t')\n",
        "            word = column[0].lower()\n",
        "            current_sentence.append(word)\n",
        "      \n",
        "      if is_labeled:\n",
        "        return sentences, tags\n",
        "      else:\n",
        "        return sentences\n",
        "\n",
        "  def get_batches(self, batch_size, vocab, tagset):\n",
        "    \"\"\"\n",
        "\n",
        "    Batches the data into mini-batches of size `batch_size`\n",
        "\n",
        "    Arguments:\n",
        "    - batch_size:       the desired output batch size\n",
        "    - vocab:            a dictionary mapping word strings to indices\n",
        "    - tagset:           a dictionary mapping tag strings to indices\n",
        "\n",
        "    Outputs:\n",
        "\n",
        "    if is_labeled=True:\n",
        "    - batched_word_indices:     a list of matrices of dimension (batch_size x max_seq_len)\n",
        "    - batched_tag_indices:      a list of matrices of dimension (batch_size x max_seq_len)\n",
        "    - batched_lengths:          a list of arrays of length (batch_size)\n",
        "\n",
        "    if is_labeled=False:\n",
        "    - batched_word_indices:     a list of matrices of dimension (batch_size x max_seq_len)\n",
        "    - batched_lengths:          a list of arrays of length (batch_size)\n",
        "\n",
        "\n",
        "    Description: \n",
        "\n",
        "    This function partitions the data into batches of size batch_size. If the number\n",
        "    of sentences in the document is not an even multiple of batch_size, the final batch\n",
        "    will contain the remaining elements. For example, if there are 82 sentences in the \n",
        "    dataset and batch_size=32, we return a list containing two batches of size 32 \n",
        "    and one final batch of size 18.\n",
        "\n",
        "    batched_word_indices[b] is a (batch_size x max_seq_len) matrix of integers, \n",
        "    containing index representations for sentences in the b-th batch in the document. \n",
        "    The `vocab` dictionary provides the correct mapping from word strings to indices. \n",
        "    If a word is not in the vocabulary, it gets mapped to UNKNOWN_INDEX (1).\n",
        "    `max_seq_len` is the maximum sentence length among the sentences in the current batch, \n",
        "    which will vary between different batches. All sentences shorter than max_seq_len \n",
        "    should be padded on the right with PAD_INDEX (0).\n",
        "\n",
        "    If the document is labeled, we also batch the document's tags. Analogous to \n",
        "    batched_word_indices, batched_tag_indices[b] contains the index representation\n",
        "    for the tags corresponding to the sentences in the b-th batch  in the document. \n",
        "    The `tagset` dictionary provides the correct mapping from tag strings to indicies. \n",
        "    All tag lists shorter than `max_seq_len` are padded with IGNORE_TAG_INDEX (-100).\n",
        "\n",
        "    batched_lengths[b] is a vector of length (batch_size). batched_lengths[b][i] \n",
        "    contains the original sentence length *before* padding for the i-th sentence\n",
        "    in the currrent batch. \n",
        "\n",
        "    \"\"\"\n",
        "    PAD_INDEX = 0             # reserved for padding words\n",
        "    UNKNOWN_INDEX = 1         # reserved for unknown words\n",
        "    IGNORE_TAG_INDEX = -100   # reserved for padding tags\n",
        "\n",
        "    # randomly shuffle the data\n",
        "    np.random.seed(159) # DON'T CHANGE THIS\n",
        "    shuffle = np.random.permutation(range(len(self.sentences)))\n",
        "\n",
        "    sentences = [self.sentences[i] for i in shuffle]\n",
        "    if self.is_labeled:\n",
        "      tags = [self.tags[i] for i in shuffle]\n",
        "    else:\n",
        "      tags = None\n",
        "    batched_word_indices = []\n",
        "    batched_tag_indices = []\n",
        "    batched_lengths = []\n",
        "    \n",
        "    #CONVERTING\n",
        "    track_words = []\n",
        "    track_tags = []\n",
        "    lengths = []\n",
        "    for sent in range(len(sentences)):\n",
        "      sent_words = []\n",
        "      sent_tags = []\n",
        "      lengths.append(len(sentences[sent]))\n",
        "      for word in range(len(sentences[sent])):\n",
        "        if self.is_labeled is True:\n",
        "          sent_tags.append(tagset[tags[sent][word]])\n",
        "          if sentences[sent][word] in vocab:\n",
        "            sent_words.append(vocab[sentences[sent][word]])\n",
        "          else:\n",
        "            sent_words.append(UNKNOWN_INDEX)\n",
        "        else:\n",
        "          if sentences[sent][word] in vocab:\n",
        "            sent_words.append(vocab[sentences[sent][word]])\n",
        "          else:\n",
        "            sent_words.append(UNKNOWN_INDEX)\n",
        "\n",
        "      track_words.append(sent_words)\n",
        "      if sent_tags != 0:\n",
        "        track_tags.append(sent_tags)\n",
        "\n",
        "    #BATCHING\n",
        "    num_of_batches = round(len(sentences)/batch_size)\n",
        "    sent_batches = []\n",
        "    tag_batches = []\n",
        "    length_batches = []\n",
        "    max_seq_batches = []\n",
        "\n",
        "    word_batches = [track_words[i:i+batch_size] for i in range(0,len(sentences),batch_size)]\n",
        "    tag_batches = [track_tags[i:i+batch_size] for i in range(0,len(sentences),batch_size)]\n",
        "    length_batches = [lengths[i:i+batch_size] for i in range(0,len(sentences),batch_size)]\n",
        "\n",
        "\n",
        "    for b in range(num_of_batches):\n",
        "      if (b+1) * batch_size <= len(sentences):\n",
        "        sent_batches = track_words[batch_size*b:batch_size*(b+1)]\n",
        "        length_batches = lengths[batch_size*b:batch_size*(b+1)]\n",
        "\n",
        "        if len(track_tags) != 0:\n",
        "          tag_batches = track_tags[batch_size*b:batch_size*(b+1)]\n",
        "      else:\n",
        "        sent_batches = track_words[batch_size*b:]\n",
        "        length_batches = lengths[batch_size*b:]\n",
        "\n",
        "        if len(track_tags) != 0:\n",
        "          tag_batches = track_tags[batch_size*b:]\n",
        "\n",
        "      max_lengths = max(length_batches)\n",
        "      batched_word_indices.append(sent_batches)\n",
        "      batched_lengths.append(length_batches)\n",
        "      max_seq_batches.append(max_lengths)\n",
        "\n",
        "      if len(track_tags) != 0:\n",
        "        batched_tag_indices.append(tag_batches)\n",
        "    #print(batched_max_seq)\n",
        "    # print(len(batched_lengths))\n",
        "    # print(len(length_batches))\n",
        "    # if end > (len(sentences)):\n",
        "    #   for i in range(start,len(sentences)):\n",
        "    #     batched_word_indices[index].append(word_indices[i])\n",
        "    #     batched_tag_indices[index].append(tag_indices[i])\n",
        "    #     batched_lengths[index].append(lengths[i])\n",
        "    # else:\n",
        "    #   for i in range(start,end):\n",
        "    #     batched_word_indices[index].append(word_indices[i])\n",
        "    #     batched_tag_indices[index].append(tag_indices[i])\n",
        "    #     batched_lengths[index].append(lengths[i])\n",
        "    # start = start + batch_size\n",
        "    # end = end + batch_size\n",
        "\n",
        "\n",
        "    # num_batches = round(len(sentences)/batch_size)\n",
        "    # start = 0\n",
        "    # end = batch_size\n",
        "    # for index in range(num_batches):\n",
        "    #   if end > (len(sentences)):\n",
        "    #     for i in range(start,len(sentences)):\n",
        "    #       batched_word_indices[index].append(word_indices[i])\n",
        "    #       batched_tag_indices[index].append(tag_indices[i])\n",
        "    #       batched_lengths[index].append(lengths[i])\n",
        "    #   else:\n",
        "    #     for i in range(start,end):\n",
        "    #       batched_word_indices[index].append(word_indices[i])\n",
        "    #       batched_tag_indices[index].append(tag_indices[i])\n",
        "    #       batched_lengths[index].append(lengths[i])\n",
        "    #   start = start + batch_size\n",
        "    #   end = end + batch_size\n",
        "\n",
        "    # max_seq_lengs = []\n",
        "    # for i in range(len(batched_word_indices)): # for every batch\n",
        "    #   max_len_this_batch = 0\n",
        "    #   for sentence in batched_word_indices[i]: #for every sentence in this batch\n",
        "    #     if len(sentence) > max_len_this_batch:\n",
        "    #       max_len_this_batch = len(sentence)\n",
        "    #   max_seq_lengs.append(max_len_this_batch)\n",
        "    \n",
        "    #PADDING\n",
        "    for b in range(len(batched_word_indices)): \n",
        "      the_max_length = max_seq_batches[b]\n",
        "      for sent in range(len(batched_word_indices[b])): \n",
        "        if len(batched_word_indices[b][sent]) < the_max_length:\n",
        "          #diff = the_max_length - len(batched_word_indices[b][sent])\n",
        "          for i in range(len(batched_word_indices[b][sent]),the_max_length):\n",
        "            batched_word_indices[b][sent].append(PAD_INDEX)\n",
        "    #for batch in range(len(batched_tag_indices)):\n",
        "      #max_seq_len = batched_max_seq[batch]\n",
        "      for t in range(len(batched_tag_indices[b])): \n",
        "        if len(batched_tag_indices[b][t]) < the_max_length:\n",
        "          #diff = the_max_length - len(batched_tag_indices[b][t])\n",
        "          for num in range(len(batched_tag_indices[b][t]),the_max_length):\n",
        "            batched_tag_indices[b][t].append(IGNORE_TAG_INDEX)\n",
        "    \n",
        "    for i in range(len(batched_word_indices)):\n",
        "      # for j in range(len(batched_word_indices[i])):\n",
        "      #   batched_word_indices[i][j] = np.array(batched_word_indices[i][j])\n",
        "      #   batched_tag_indices[i][j] = np.array(batched_tag_indices[i][j])\n",
        "      batched_word_indices[i] = np.array(batched_word_indices[i])\n",
        "      batched_tag_indices[i] = np.array(batched_tag_indices[i])\n",
        "      batched_lengths[i] = np.array(batched_lengths[i])\n",
        "      \n",
        "    \n",
        "    print(sentences[0])\n",
        "    if tags != None:\n",
        "      print(tags[0])\n",
        "    print(batched_word_indices[0][0])\n",
        "    print(type(batched_word_indices[0][0]))\n",
        "    \n",
        "    #############################\n",
        "    #       DO NOT MODIFY       #\n",
        "    #############################\n",
        "    if self.is_labeled:\n",
        "      return batched_word_indices, batched_tag_indices, batched_lengths\n",
        "    else:\n",
        "      return batched_word_indices, batched_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ePEcb46_zGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_tagset(tag_file):\n",
        "  \"\"\"\n",
        "  Utility function, loads tag file into a dictionary from tag string to tag index\n",
        "\n",
        "  Arguments:\n",
        "  - tag_file:   file location of the tagset\n",
        "\n",
        "  Outputs:\n",
        "  - tagset:     a dictionary mapping tag strings (e.g. \"VB\") to a unique index\n",
        "  \"\"\"\n",
        "  tagset = {}\n",
        "  with open(tag_file, encoding='utf8') as f:\n",
        "    for line in f:\n",
        "      columns = line.rstrip().split('\\t')\n",
        "      tag = columns[0]\n",
        "      tag_id = int(columns[1])\n",
        "      tagset[tag] = tag_id\n",
        "  \n",
        "  return tagset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mMQIJ_vVuiz",
        "colab_type": "text"
      },
      "source": [
        "The cells below download the data files and construct the corresponding `Dataset` objects. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhXTkpTqGR1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.train\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.dev\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.test\n",
        "!wget https://raw.githubusercontent.com/dbamman/nlp20/master/HW_4/pos.tagset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vtP5seIgBORT",
        "outputId": "5be30a55-cb02-4635-a492-a28a9f51a764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "# read the files\n",
        "tagset = read_tagset('pos.tagset')\n",
        "train_dataset = Dataset('pos.train', is_labeled=True)\n",
        "dev_dataset = Dataset('pos.dev', is_labeled=True)\n",
        "test_dataset = Dataset('pos.test', is_labeled=False)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# these should run without errors if implemented correctly\n",
        "train_batch_idx, train_batch_tags, train_batch_lens = train_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "dev_batch_idx, dev_batch_tags, dev_batch_lens = dev_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "test_batch_idx, test_batch_lens = test_dataset.get_batches(BATCH_SIZE, vocab, tagset)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['to', 'approve', ':', 'right', 'mouse', 'click', 'on', '\"', 'approved', '\"']\n",
            "['TO', 'VB', ':', 'JJ', 'NN', 'VB', 'IN', '``', 'NN', \"''\"]\n",
            "[   6 4668   47  250 7573 9643   15   10 1414   10    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n",
            "<class 'numpy.ndarray'>\n",
            "['you', 'have', 'received', 'this', 'bbc', 'breaking', 'news', 'alert', 'because', 'you', 'subscribed', 'to', 'it', 'or', ',', 'someone', 'forwarded', 'it', 'to', 'you', '.']\n",
            "['PRP', 'VBP', 'VBN', 'DT', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'PRP', 'VBD', 'IN', 'PRP', 'CC', ',', 'NN', 'VBD', 'PRP', 'IN', 'PRP', '.']\n",
            "[  83   35  498   39 3094 2925  174 3641  115   83    1    6   22   48\n",
            "    3 1320    1   22    6   83    4    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "<class 'numpy.ndarray'>\n",
            "['ps', 'i', 'may', 'have', 'to', 'come', 'back', 'to', 'work', 'for', 'a', '615', 'call']\n",
            "[  1  43 109  35   6 328 139   6 163  12   9   1 582   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-nnX7WxqDJ3",
        "colab_type": "text"
      },
      "source": [
        "### Part 2: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMSHWADzpaBL",
        "colab_type": "code",
        "outputId": "37784187-f596-456d-c7bd-404e63cb4fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(train_batch_idx[0])"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMtkCBt_wzIS",
        "colab_type": "text"
      },
      "source": [
        "Next, we will implement utility functions that will later be used to assess our model's perfomance. \n",
        "\n",
        "**Please make sure that**\n",
        "\n",
        "*   Your implementation is self-contained. That is, keep all helper functions or variables inside of your function.\n",
        "*   Your implementation does not import any additional libraries. You will not receive credit if you do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQLiM0ukG-4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The accuracy function has been implemented for you\n",
        "\n",
        "def accuracy(true, pred):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "\n",
        "  Output:\n",
        "  - accuracy:   the prediction accuracy\n",
        "  \"\"\"\n",
        "  true = np.array(true)\n",
        "  pred = np.array(pred)\n",
        "\n",
        "  num_correct = sum(true == pred)\n",
        "  num_total = len(true)\n",
        "  return num_correct / num_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChJjUu45qFM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confusion_matrix(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - confusion_matrix:   a (num_tags x num_tags) matrix of integers\n",
        "\n",
        "  confusion_matrix[i][j] = # predictions where true label\n",
        "  was i and predicted label was j\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  confusion_matrix = np.zeros((num_tags, num_tags))\n",
        "  for index in range(len(true)):\n",
        "    confusion_matrix[true[index]][pred[index]] += 1\n",
        "\n",
        "  return confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EopJYDDNoPh",
        "colab_type": "code",
        "outputId": "fe129946-5a18-41f0-a53d-4f76ccd5f854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "true = [1,2,4,5]\n",
        "pred = [1,2,3,7]\n",
        "num_tags=8\n",
        "cm = confusion_matrix(true,pred,num_tags)\n",
        "cm"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hdj6QSaBV9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precision(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - precision:  an array of length num_tags, where precision[i]\n",
        "                gives the precision of class i\n",
        "\n",
        "  Hints:  the confusion matrix may be useful\n",
        "          be careful about zero division\n",
        "  \"\"\"\n",
        "\n",
        "  precision = np.zeros(num_tags)\n",
        "  c_m = confusion_matrix(true,pred,num_tags)\n",
        "  #column = confusion_matrix.T\n",
        "  for i in range(num_tags):\n",
        "    num = c_m[i][i]\n",
        "    col = c_m[:, i]\n",
        "    col_sum = sum(col)\n",
        "    if col_sum != 0:\n",
        "      sum_this_col = num/col_sum\n",
        "      precision[i] = sum_this_col\n",
        "    else:\n",
        "      precision[i] = 0\n",
        "  return precision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDzxgjaxTds5",
        "colab_type": "code",
        "outputId": "29e12722-1b58-4bd2-c7a9-a446ccec4574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "true = [2,3,2,5,3]\n",
        "pred = [1,3,4,2,2]\n",
        "num_tags=8\n",
        "precision(true,pred,num_tags)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJL55TnOBVxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - recall:     an array of length num_tags, where recall[i]\n",
        "                gives the recall of class i\n",
        "\n",
        "  Hints:  the confusion matrix may be useful\n",
        "          be careful about zero division\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  YOUR CODE HERE\n",
        "  \"\"\"\n",
        "  recall = np.zeros(num_tags)\n",
        "  c_m = confusion_matrix(true,pred,num_tags)\n",
        "  for i in range(num_tags):\n",
        "    num = c_m[i][i]\n",
        "    row = c_m[i,:]\n",
        "    row_sum = sum(row)\n",
        "    if row_sum != 0:\n",
        "      sum_this_row = num/row_sum\n",
        "      recall[i] = sum_this_row\n",
        "    else:\n",
        "      recall[i] = 0\n",
        "  return recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpQTR3PQbYeT",
        "colab_type": "code",
        "outputId": "24332f8c-8065-4fbb-9f05-c04349401b03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "true = [2,3,4,5,6]\n",
        "pred = [2,3,7,6,6]\n",
        "num_tags=8\n",
        "recal = recall(true,pred,num_tags)\n",
        "recal"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 1., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7drr7z1VBVjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1_score(true, pred, num_tags):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  - true:       a list of true label values (integers)\n",
        "  - pred:       a list of predicted label values (integers)\n",
        "  - num_tags:   the number of possible tags\n",
        "                true and pred will both contain integers between\n",
        "                0 and num_tags - 1 (inclusive)\n",
        "\n",
        "  Output: \n",
        "  - f1:         an array of length num_tags, where f1[i]\n",
        "                gives the recall of class i\n",
        "  \"\"\"\n",
        "  f1 = np.zeros(num_tags)\n",
        "  re = recall(true,pred,num_tags)\n",
        "  pre = precision(true,pred,num_tags)\n",
        "  for i in range(num_tags):\n",
        "    numerator = pre[i]*re[i]\n",
        "    denomenator = pre[i] + re[i]\n",
        "    if pre[i] == 0 or re[i] == 0:\n",
        "      f1_indiv = 0\n",
        "      f1[i] = f1_indiv\n",
        "    else:\n",
        "      f1_indiv = 2*(numerator/denomenator)\n",
        "      f1[i] = f1_indiv\n",
        "\n",
        "  return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFiq8W51bO8z",
        "colab_type": "code",
        "outputId": "1ce1ebd5-bc8e-42d0-e7d7-076758d11710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "true = [5,6,6,2,3]\n",
        "pred = [5,6,7,2,3]\n",
        "num_tags=8\n",
        "f = f1_score(true,pred,num_tags)\n",
        "f"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 1.        , 1.        , 0.        ,\n",
              "       1.        , 0.66666667, 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS1p55P5UGv4",
        "colab_type": "text"
      },
      "source": [
        "### Part 3: Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IPoFwqfoFOO",
        "colab_type": "text"
      },
      "source": [
        "Fill in the blanks in `LSTMTagger`'s `__init__` function. If you get stuck, you can reference PyTorch's [torch.nn documentation](https://pytorch.org/docs/stable/nn.html) or [this official tutorial](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html) on LSTM sequence labeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6J3z3T0USI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "  \"\"\"\n",
        "  An LSTM model for sequence labeling\n",
        "\n",
        "  Initialization Arguments:\n",
        "  - embeddings:   a matrix of size (vocab_size, emb_dim)\n",
        "                  containing pretrained embedding weights\n",
        "  - hidden_dim:   the LSTM's hidden layer size\n",
        "  - tagset_size:  the number of possible output tags\n",
        "\n",
        "  \"\"\"\n",
        " \n",
        "  def __init__(self, embeddings, hidden_dim, tagset_size):\n",
        "    super().__init__()\n",
        "  \n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.num_labels = tagset_size\n",
        "\n",
        "    # Initialize a PyTorch embeddings layer using the pretrained embedding weights\n",
        "    vocab_size,em_dim = embeddings.shape\n",
        "    #print(embeddings.shape)\n",
        "    self.embeddings = torch.nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
        "    #torch.size([10000,50])\n",
        "\n",
        "    # Initialize an LSTM layer\n",
        "    self.lstm = torch.nn.LSTM(em_dim,hidden_dim)\n",
        "\n",
        "    # Initialize a single feedforward layer\n",
        "    self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
        "    \n",
        "  def forward(self, indices, lengths):\n",
        "    \"\"\"\n",
        "    Runs a batched sequence through the model and returns output logits\n",
        "\n",
        "    Arguments:\n",
        "    - indices:  a matrix of size (batch_size x max_seq_len)\n",
        "                containing the word indices of sentences in the batch\n",
        "    - lengths:  a vector of size (batch_size) containing the\n",
        "                original lengths of the sequences before padding\n",
        "\n",
        "    Output:\n",
        "    - logits:   a matrix of size (batch_size x max_seq_len x num_tags)\n",
        "                gives a score to each possible tag for each word\n",
        "                in each sentence \n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # cast arrays as PyTorch data types and move to GPU memory\n",
        "    #print(type(indices[0]))\n",
        "    #print(indices.shape)\n",
        "    indices = torch.LongTensor(indices).to(device)\n",
        "    lengths = torch.LongTensor(lengths).to(device)\n",
        "    \n",
        "    # convert word indices to word embeddings\n",
        "    embeddings = self.embeddings(indices)\n",
        "\n",
        "    # pack/pad handles variable length sequence batching\n",
        "    # see here if you're curious: https://gist.github.com/HarshTrivedi/f4e7293e941b17d19058f6fb90ab0fec\n",
        "    packed_input_embs = pack_padded_sequence(embeddings, lengths, batch_first=True, enforce_sorted=False)\n",
        "    # run input through LSTM layer\n",
        "    packed_output, _ = self.lstm(packed_input_embs)\n",
        "    # unpack sequences into original format\n",
        "    padded_output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "    logits = self.hidden2tag(padded_output)\n",
        "    return logits\n",
        "\n",
        "  def run_training(self, train_dataset, dev_dataset, batch_size, vocab, tagset,\n",
        "                         lr=5e-4, num_epochs=100, eval_every=5):\n",
        "    \"\"\"\n",
        "    Trains the model on the training data with a learning rate of lr\n",
        "    for num_epochs. Evaluates the model on the dev data eval_every epochs.\n",
        "\n",
        "    Arguments:\n",
        "    - train_dataset:  Dataset object containing the training data\n",
        "    - dev_dataset:    Dataset object containing the dev data\n",
        "    - batch_size:     batch size for train/dev data\n",
        "    - vocab:          a dictionary mapping word strings to indices\n",
        "    - tagset:         a dictionary mapping tag strings to indices\n",
        "    - lr:             learning rate\n",
        "    - num_epochs:     number of epochs to train for\n",
        "    - eval_every:     evaluation is run eval_every epochs\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if str(device) == 'cpu':\n",
        "      print(\"Training only supported in GPU environment\")\n",
        "      return\n",
        "\n",
        "    # clear unreferenced data/models from GPU memory \n",
        "    torch.cuda.empty_cache()\n",
        "    # move model to GPU memory\n",
        "    self.to(device)\n",
        "\n",
        "    # set the optimizer (Adam) and loss function (CrossEnt)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_function = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n",
        "    # batch training and dev data\n",
        "    train_batch_idx, train_batch_tags, train_batch_lens = train_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "    dev_batch_idx, dev_batch_tags, dev_batch_lens = dev_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "\n",
        "    print(\"**** TRAINING *****\")\n",
        "    for i in range(num_epochs):\n",
        "      # sets the model in train mode\n",
        "      self.train()\n",
        "\n",
        "      total_loss = 0\n",
        "      for b in range(len(train_batch_idx)):\n",
        "        # compute the logits\n",
        "        logits = model.forward(train_batch_idx[b], train_batch_lens[b])\n",
        "        # move labels to GPU memory\n",
        "        labels = torch.LongTensor(train_batch_tags[b]).to(device)\n",
        "        # compute the loss with respect to true labels\n",
        "        loss = loss_function(logits.view(-1, len(tagset)), labels.view(-1))\n",
        "        total_loss += loss\n",
        "        # propagate gradients backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # set model gradients to zero before performing next forward pass\n",
        "        self.zero_grad()\n",
        "\n",
        "      print(\"Epoch {} | Loss: {}\".format(i, total_loss))\n",
        "\n",
        "      if (i + 1) % eval_every == 0:\n",
        "        print(\"**** EVALUATION *****\")\n",
        "        # sets the model in evaluate mode (no gradients)\n",
        "        self.eval()\n",
        "        # compute dev f1 score\n",
        "        acc, true, pred = self.evaluate(dev_batch_idx, dev_batch_lens, dev_batch_tags, tagset)\n",
        "        print(\"Dev Accuracy: {}\".format(acc))\n",
        "        print(\"**********************\")\n",
        "\n",
        "  def evaluate(self, batched_sentences, batched_lengths, batched_labels, tagset):\n",
        "    \"\"\"\n",
        "    Evaluate the model's predictions on the provided dataset. \n",
        "\n",
        "    Arguments:\n",
        "    - batched_sentences:  a list of matrices, each of size (batch_size x max_seq_len),\n",
        "                          containing the word indices of sentences in the batch\n",
        "    - batched_lengths:    a list of vectors, each of size (batch_size), containing the\n",
        "                          original lengths of the sequences before padding\n",
        "    - batched_labels:     a list of matrices, each of size (batch_size x max_seq_len),\n",
        "                          containing the tag indices corresponding to sentences in the batch\n",
        "    - num_tags:           the number of possible output tags\n",
        "\n",
        "    Output:\n",
        "    - accuracy:           the model's prediction accuracy\n",
        "    - all_true_labels:    a flattened list of all true labels\n",
        "    - all_predictions:    a flattened list of all of the model's corresponding predictions\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    for b in range(len(batched_sentences)):\n",
        "      logits = self.forward(batched_sentences[b], batched_lengths[b])\n",
        "      batch_predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "      batch_size, _ = batched_sentences[b].shape\n",
        "\n",
        "      for i in range(batch_size):\n",
        "        tags = batched_labels[b][i]\n",
        "        preds = batch_predictions[i]\n",
        "        \n",
        "        seq_len = int(batched_lengths[b][i])\n",
        "        for j in range(seq_len):\n",
        "          all_predictions.append(int(preds[j]))\n",
        "          all_true_labels.append(int(tags[j]))\n",
        "      \n",
        "    \n",
        "    acc = accuracy(all_true_labels, all_predictions)\n",
        "      \n",
        "    return acc, all_true_labels, all_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4AOB94R9RFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed):\n",
        "  \"\"\"\n",
        "  Sets random seeds and sets model in deterministic\n",
        "  training mode. Ensures reproducible results\n",
        "  \"\"\"\n",
        "  torch.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AuNeDk9qAM_",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WTEvLeVuNWl",
        "colab_type": "text"
      },
      "source": [
        "Run the cells below to train your model. If all of the previous sections are implemented correctly, you should see\n",
        "\n",
        "\n",
        "*   the loss decreasing consistently for every epoch\n",
        "*   the dev accuracy increasing until convergence around ~0.88\n",
        "\n",
        "The staff solution achieves an accuracy of 0.880 after 25 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9NqwYnfU2WB",
        "colab_type": "code",
        "outputId": "ab2a6cc3-aabc-4af9-cbb5-c37a9548b3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# sets the random seed – DO NOT change this\n",
        "# this ensures deterministic results that are comparable with the staff values\n",
        "set_seed(159)\n",
        "\n",
        "HIDDEN_SIZE = 64\n",
        "# intialize a new LSTMTagger model\n",
        "model = LSTMTagger(embeddings, HIDDEN_SIZE, len(tagset))\n",
        "# train the model\n",
        "model.run_training(train_dataset, dev_dataset, BATCH_SIZE, vocab, tagset,   \n",
        "                   lr=5e-4, num_epochs=25, eval_every=5)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['to', 'approve', ':', 'right', 'mouse', 'click', 'on', '\"', 'approved', '\"']\n",
            "['TO', 'VB', ':', 'JJ', 'NN', 'VB', 'IN', '``', 'NN', \"''\"]\n",
            "[   6 4668   47  250 7573 9643   15   10 1414   10    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n",
            "<class 'numpy.ndarray'>\n",
            "['you', 'have', 'received', 'this', 'bbc', 'breaking', 'news', 'alert', 'because', 'you', 'subscribed', 'to', 'it', 'or', ',', 'someone', 'forwarded', 'it', 'to', 'you', '.']\n",
            "['PRP', 'VBP', 'VBN', 'DT', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'PRP', 'VBD', 'IN', 'PRP', 'CC', ',', 'NN', 'VBD', 'PRP', 'IN', 'PRP', '.']\n",
            "[  83   35  498   39 3094 2925  174 3641  115   83    1    6   22   48\n",
            "    3 1320    1   22    6   83    4    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "<class 'numpy.ndarray'>\n",
            "**** TRAINING *****\n",
            "Epoch 0 | Loss: 999.9422607421875\n",
            "Epoch 1 | Loss: 442.2580871582031\n",
            "Epoch 2 | Loss: 275.37127685546875\n",
            "Epoch 3 | Loss: 212.16627502441406\n",
            "Epoch 4 | Loss: 181.42295837402344\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8586200039769338\n",
            "**********************\n",
            "Epoch 5 | Loss: 163.11807250976562\n",
            "Epoch 6 | Loss: 150.56387329101562\n",
            "Epoch 7 | Loss: 141.14601135253906\n",
            "Epoch 8 | Loss: 133.68817138671875\n",
            "Epoch 9 | Loss: 127.54783630371094\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8754026645456353\n",
            "**********************\n",
            "Epoch 10 | Loss: 122.3573989868164\n",
            "Epoch 11 | Loss: 117.87614440917969\n",
            "Epoch 12 | Loss: 113.9259033203125\n",
            "Epoch 13 | Loss: 110.38809967041016\n",
            "Epoch 14 | Loss: 107.16903686523438\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8791409823026447\n",
            "**********************\n",
            "Epoch 15 | Loss: 104.20203399658203\n",
            "Epoch 16 | Loss: 101.439453125\n",
            "Epoch 17 | Loss: 98.83808135986328\n",
            "Epoch 18 | Loss: 96.3730239868164\n",
            "Epoch 19 | Loss: 94.02763366699219\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8803738317757009\n",
            "**********************\n",
            "Epoch 20 | Loss: 91.78712463378906\n",
            "Epoch 21 | Loss: 89.6347427368164\n",
            "Epoch 22 | Loss: 87.56658172607422\n",
            "Epoch 23 | Loss: 85.56128692626953\n",
            "Epoch 24 | Loss: 83.62177276611328\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.8802147544243388\n",
            "**********************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH5giKgvJp0c",
        "colab_type": "text"
      },
      "source": [
        "Once the model is trained, run the cells below to print the precision, recall, and $F_1$ score per class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLqaZ_6cMMPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_per_class(model, dataset, vocab, tagset):\n",
        "  \"\"\"\n",
        "  Prints precision, recall, and F1 for each class in the tagset\n",
        "  \"\"\"\n",
        "  # batch the data\n",
        "  batched_idx, batched_tags, batched_lens = dev_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "  # compute idx --> tag from tag --> idx\n",
        "  reverse_tagset = {v: k for k,v in tagset.items()}\n",
        "  # evaluate model on hold-out set\n",
        "  acc, true, pred = model.evaluate(batched_idx, batched_lens, batched_tags, tagset)\n",
        "  true = np.array(true)\n",
        "  pred = np.array(pred)\n",
        "\n",
        "  pr = precision(true, pred, len(tagset))\n",
        "  re = recall(true, pred, len(tagset))\n",
        "  f1 = f1_score(true, pred, len(tagset))\n",
        "\n",
        "  for idx, tag in reverse_tagset.items():\n",
        "    print(\"***********************\")\n",
        "    print(\"TAG: {}\".format(tag))\n",
        "    num_pred = np.sum(pred == idx)\n",
        "    num_true = np.sum(true == idx)\n",
        "    print(\"({} pred, {} true)\".format(num_pred, num_true))\n",
        "\n",
        "    print(\"PRECISION: \\t{:.3f}\".format(pr[idx]))\n",
        "    print(\"RECALL: \\t{:.3f}\".format(re[idx]))\n",
        "    print(\"F1 SCORE: \\t{:.3f}\".format(f1[idx]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tTEpCBsuYuP",
        "colab_type": "code",
        "outputId": "afb00eae-2ccf-4481-cf6c-9c76ee4e1c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "eval_per_class(model, dev_dataset, vocab, tagset)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['you', 'have', 'received', 'this', 'bbc', 'breaking', 'news', 'alert', 'because', 'you', 'subscribed', 'to', 'it', 'or', ',', 'someone', 'forwarded', 'it', 'to', 'you', '.']\n",
            "['PRP', 'VBP', 'VBN', 'DT', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'PRP', 'VBD', 'IN', 'PRP', 'CC', ',', 'NN', 'VBD', 'PRP', 'IN', 'PRP', '.']\n",
            "[  83   35  498   39 3094 2925  174 3641  115   83    1    6   22   48\n",
            "    3 1320    1   22    6   83    4    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "<class 'numpy.ndarray'>\n",
            "***********************\n",
            "TAG: $\n",
            "(13 pred, 14 true)\n",
            "PRECISION: \t1.000\n",
            "RECALL: \t0.929\n",
            "F1 SCORE: \t0.963\n",
            "***********************\n",
            "TAG: ''\n",
            "(85 pred, 88 true)\n",
            "PRECISION: \t0.882\n",
            "RECALL: \t0.852\n",
            "F1 SCORE: \t0.867\n",
            "***********************\n",
            "TAG: ,\n",
            "(949 pred, 936 true)\n",
            "PRECISION: \t0.954\n",
            "RECALL: \t0.967\n",
            "F1 SCORE: \t0.960\n",
            "***********************\n",
            "TAG: -LRB-\n",
            "(107 pred, 117 true)\n",
            "PRECISION: \t0.972\n",
            "RECALL: \t0.889\n",
            "F1 SCORE: \t0.929\n",
            "***********************\n",
            "TAG: -RRB-\n",
            "(117 pred, 120 true)\n",
            "PRECISION: \t0.949\n",
            "RECALL: \t0.925\n",
            "F1 SCORE: \t0.937\n",
            "***********************\n",
            "TAG: .\n",
            "(1461 pred, 1503 true)\n",
            "PRECISION: \t0.988\n",
            "RECALL: \t0.960\n",
            "F1 SCORE: \t0.974\n",
            "***********************\n",
            "TAG: :\n",
            "(103 pred, 106 true)\n",
            "PRECISION: \t0.922\n",
            "RECALL: \t0.896\n",
            "F1 SCORE: \t0.909\n",
            "***********************\n",
            "TAG: ADD\n",
            "(19 pred, 81 true)\n",
            "PRECISION: \t0.368\n",
            "RECALL: \t0.086\n",
            "F1 SCORE: \t0.140\n",
            "***********************\n",
            "TAG: AFX\n",
            "(1 pred, 4 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: CC\n",
            "(780 pred, 781 true)\n",
            "PRECISION: \t0.990\n",
            "RECALL: \t0.988\n",
            "F1 SCORE: \t0.989\n",
            "***********************\n",
            "TAG: CD\n",
            "(325 pred, 378 true)\n",
            "PRECISION: \t0.858\n",
            "RECALL: \t0.738\n",
            "F1 SCORE: \t0.794\n",
            "***********************\n",
            "TAG: DT\n",
            "(1967 pred, 1943 true)\n",
            "PRECISION: \t0.970\n",
            "RECALL: \t0.982\n",
            "F1 SCORE: \t0.976\n",
            "***********************\n",
            "TAG: EX\n",
            "(51 pred, 56 true)\n",
            "PRECISION: \t0.961\n",
            "RECALL: \t0.875\n",
            "F1 SCORE: \t0.916\n",
            "***********************\n",
            "TAG: FW\n",
            "(2 pred, 30 true)\n",
            "PRECISION: \t1.000\n",
            "RECALL: \t0.067\n",
            "F1 SCORE: \t0.125\n",
            "***********************\n",
            "TAG: GW\n",
            "(16 pred, 32 true)\n",
            "PRECISION: \t0.375\n",
            "RECALL: \t0.188\n",
            "F1 SCORE: \t0.250\n",
            "***********************\n",
            "TAG: HYPH\n",
            "(89 pred, 95 true)\n",
            "PRECISION: \t0.854\n",
            "RECALL: \t0.800\n",
            "F1 SCORE: \t0.826\n",
            "***********************\n",
            "TAG: IN\n",
            "(2461 pred, 2353 true)\n",
            "PRECISION: \t0.909\n",
            "RECALL: \t0.951\n",
            "F1 SCORE: \t0.929\n",
            "***********************\n",
            "TAG: JJ\n",
            "(1730 pred, 1655 true)\n",
            "PRECISION: \t0.810\n",
            "RECALL: \t0.847\n",
            "F1 SCORE: \t0.828\n",
            "***********************\n",
            "TAG: JJR\n",
            "(40 pred, 47 true)\n",
            "PRECISION: \t0.675\n",
            "RECALL: \t0.574\n",
            "F1 SCORE: \t0.621\n",
            "***********************\n",
            "TAG: JJS\n",
            "(69 pred, 84 true)\n",
            "PRECISION: \t0.913\n",
            "RECALL: \t0.750\n",
            "F1 SCORE: \t0.824\n",
            "***********************\n",
            "TAG: LS\n",
            "(9 pred, 5 true)\n",
            "PRECISION: \t0.333\n",
            "RECALL: \t0.600\n",
            "F1 SCORE: \t0.429\n",
            "***********************\n",
            "TAG: MD\n",
            "(356 pred, 358 true)\n",
            "PRECISION: \t0.986\n",
            "RECALL: \t0.980\n",
            "F1 SCORE: \t0.983\n",
            "***********************\n",
            "TAG: NFP\n",
            "(30 pred, 60 true)\n",
            "PRECISION: \t0.767\n",
            "RECALL: \t0.383\n",
            "F1 SCORE: \t0.511\n",
            "***********************\n",
            "TAG: NN\n",
            "(3495 pred, 3336 true)\n",
            "PRECISION: \t0.813\n",
            "RECALL: \t0.851\n",
            "F1 SCORE: \t0.832\n",
            "***********************\n",
            "TAG: NNP\n",
            "(2048 pred, 1816 true)\n",
            "PRECISION: \t0.662\n",
            "RECALL: \t0.746\n",
            "F1 SCORE: \t0.701\n",
            "***********************\n",
            "TAG: NNPS\n",
            "(23 pred, 63 true)\n",
            "PRECISION: \t0.783\n",
            "RECALL: \t0.286\n",
            "F1 SCORE: \t0.419\n",
            "***********************\n",
            "TAG: NNS\n",
            "(975 pred, 929 true)\n",
            "PRECISION: \t0.790\n",
            "RECALL: \t0.829\n",
            "F1 SCORE: \t0.809\n",
            "***********************\n",
            "TAG: PDT\n",
            "(2 pred, 21 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: POS\n",
            "(85 pred, 84 true)\n",
            "PRECISION: \t0.953\n",
            "RECALL: \t0.964\n",
            "F1 SCORE: \t0.959\n",
            "***********************\n",
            "TAG: PRP\n",
            "(1486 pred, 1487 true)\n",
            "PRECISION: \t0.990\n",
            "RECALL: \t0.989\n",
            "F1 SCORE: \t0.990\n",
            "***********************\n",
            "TAG: PRP$\n",
            "(313 pred, 315 true)\n",
            "PRECISION: \t0.984\n",
            "RECALL: \t0.978\n",
            "F1 SCORE: \t0.981\n",
            "***********************\n",
            "TAG: RB\n",
            "(1152 pred, 1292 true)\n",
            "PRECISION: \t0.909\n",
            "RECALL: \t0.810\n",
            "F1 SCORE: \t0.857\n",
            "***********************\n",
            "TAG: RBR\n",
            "(30 pred, 22 true)\n",
            "PRECISION: \t0.433\n",
            "RECALL: \t0.591\n",
            "F1 SCORE: \t0.500\n",
            "***********************\n",
            "TAG: RBS\n",
            "(20 pred, 20 true)\n",
            "PRECISION: \t0.650\n",
            "RECALL: \t0.650\n",
            "F1 SCORE: \t0.650\n",
            "***********************\n",
            "TAG: RP\n",
            "(64 pred, 75 true)\n",
            "PRECISION: \t0.703\n",
            "RECALL: \t0.600\n",
            "F1 SCORE: \t0.647\n",
            "***********************\n",
            "TAG: SYM\n",
            "(4 pred, 20 true)\n",
            "PRECISION: \t0.750\n",
            "RECALL: \t0.150\n",
            "F1 SCORE: \t0.250\n",
            "***********************\n",
            "TAG: TO\n",
            "(347 pred, 359 true)\n",
            "PRECISION: \t0.859\n",
            "RECALL: \t0.830\n",
            "F1 SCORE: \t0.844\n",
            "***********************\n",
            "TAG: UH\n",
            "(61 pred, 116 true)\n",
            "PRECISION: \t0.918\n",
            "RECALL: \t0.483\n",
            "F1 SCORE: \t0.633\n",
            "***********************\n",
            "TAG: VB\n",
            "(1074 pred, 1122 true)\n",
            "PRECISION: \t0.926\n",
            "RECALL: \t0.887\n",
            "F1 SCORE: \t0.906\n",
            "***********************\n",
            "TAG: VBD\n",
            "(509 pred, 520 true)\n",
            "PRECISION: \t0.888\n",
            "RECALL: \t0.869\n",
            "F1 SCORE: \t0.879\n",
            "***********************\n",
            "TAG: VBG\n",
            "(342 pred, 384 true)\n",
            "PRECISION: \t0.874\n",
            "RECALL: \t0.779\n",
            "F1 SCORE: \t0.824\n",
            "***********************\n",
            "TAG: VBN\n",
            "(480 pred, 476 true)\n",
            "PRECISION: \t0.844\n",
            "RECALL: \t0.851\n",
            "F1 SCORE: \t0.847\n",
            "***********************\n",
            "TAG: VBP\n",
            "(770 pred, 771 true)\n",
            "PRECISION: \t0.921\n",
            "RECALL: \t0.920\n",
            "F1 SCORE: \t0.920\n",
            "***********************\n",
            "TAG: VBZ\n",
            "(648 pred, 643 true)\n",
            "PRECISION: \t0.952\n",
            "RECALL: \t0.960\n",
            "F1 SCORE: \t0.956\n",
            "***********************\n",
            "TAG: WDT\n",
            "(105 pred, 106 true)\n",
            "PRECISION: \t0.790\n",
            "RECALL: \t0.783\n",
            "F1 SCORE: \t0.787\n",
            "***********************\n",
            "TAG: WP\n",
            "(120 pred, 113 true)\n",
            "PRECISION: \t0.900\n",
            "RECALL: \t0.956\n",
            "F1 SCORE: \t0.927\n",
            "***********************\n",
            "TAG: WP$\n",
            "(0 pred, 2 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: WRB\n",
            "(112 pred, 113 true)\n",
            "PRECISION: \t1.000\n",
            "RECALL: \t0.991\n",
            "F1 SCORE: \t0.996\n",
            "***********************\n",
            "TAG: XX\n",
            "(0 pred, 3 true)\n",
            "PRECISION: \t0.000\n",
            "RECALL: \t0.000\n",
            "F1 SCORE: \t0.000\n",
            "***********************\n",
            "TAG: ``\n",
            "(100 pred, 91 true)\n",
            "PRECISION: \t0.840\n",
            "RECALL: \t0.923\n",
            "F1 SCORE: \t0.880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lefzFwCD8AJU",
        "colab_type": "text"
      },
      "source": [
        "## Part 4: Model Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxZ_Wn75uw7n",
        "colab_type": "text"
      },
      "source": [
        "Congratulations, you've just trained a neural network!\n",
        "\n",
        "Now, improve the `LSTMTagger` model and implementing the `init` function in the `FancyTagger` class below. \n",
        "* Feel free to replace the `forward` function inherited from `LSTMTagger` if \n",
        "you need to, but it should not be necessary to receive full credit. Credit will be awarded based on the performance on a holdout test set. \n",
        "* Do not modify any of the cells above when completing part 4. Instead, insert cells below if you need to perform any additional computations. \n",
        "* You are allowed to use any function in `torch.nn`. You are **not** allowed to import any libraries or use implementations copied from the internet. \n",
        "\n",
        "Before submitting, please describe your modifications below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ya-aaGh6l8D",
        "colab_type": "text"
      },
      "source": [
        "I decided to implement 2 layers of the LSTM. I also decided to make the LSTM bidirectional. I also chose to use different word embeddings; I loaded 80,000 200-dimensional embeddings, and created a hidden layer of 512 which I divided by 2 in the init() function of FancyTagger()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKz2PLbu5d8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FancyTagger(LSTMTagger):\n",
        "  \"\"\"\n",
        "  An improved neural model for sequence labeling\n",
        "\n",
        "  Starter code from LSTMTagger has already been provided, but\n",
        "  feel free to change the init and forward function internals\n",
        "  if your model design requires it (though this is not necessary\n",
        "  to receive full credit).\n",
        "\n",
        "  You may use any component in torch.nn. You may NOT\n",
        "  import any additional libraries/modules. \n",
        "\n",
        "  \"\"\"\n",
        "  #increase dim of embeddings (4000000,300) and lstm\n",
        "  #50%drop out pretty high, more likely to overfit with more parameters\n",
        "  def __init__(self, embeddings, hidden_dim, tagset_size):\n",
        "    # initializes the parent LSTMTagger class\n",
        "    # inherits forward, evaluate, and run_training methods\n",
        "    super().__init__(embeddings, hidden_dim, tagset_size)\n",
        "    #embeddings,vocab = read_embeddings('glove.6B.300d.txt',vocab_size=100000)\n",
        "    #print(hidden_dim)\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.num_labels = tagset_size\n",
        "    self.hidden_dim = int(self.hidden_dim/2)\n",
        "    #self.embeddings = torch.nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
        "    vocab_size,em_dim = embeddings.shape\n",
        "    self.lstm = torch.nn.LSTM(em_dim,self.hidden_dim,num_layers=2,bidirectional=True)\n",
        "    \n",
        "    #num_layers=2 makes the accurary drop to ~0.13\n",
        "    #num_layers=5 makes the accuracy drop to ~0.13\n",
        "    #bias = false, dev acc starts at .89, gets to .9055\n",
        "    #dropout=0.5 gets dev acc starting at 0.894, gets to 0.9076 same with .2\n",
        "    '''num_layers=2,bias=False,dropout=1,bidirectional=True)\n",
        "    vocab_size,em_dim = embeddings.shape\n",
        "    #print(embeddings.shape)\n",
        "    self.embeddings = torch.nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
        "    #torch.size([10000,50])\n",
        "\n",
        "    # Initialize an LSTM layer\n",
        "    self.lstm = torch.nn.LSTM(em_dim,hidden_dim)\n",
        "\n",
        "    # Initialize a single feedforward layer\n",
        "    self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
        "    '''\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGDY4ymJvo3h",
        "colab_type": "text"
      },
      "source": [
        "Run the training script below to train the `FancyTagger` model. Again, feel free to adjust any hyperparameters if necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lnp-tWl9Vbo",
        "colab_type": "code",
        "outputId": "de40befa-c021-4c2b-8d21-297b1646505d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "embeddings,vocab = read_embeddings('glove.6B.200d.txt',vocab_size*8)\n",
        "HIDDEN_SIZE = 512\n",
        "model = FancyTagger(embeddings, HIDDEN_SIZE, len(tagset))\n",
        "print(model)\n",
        "model.run_training(train_dataset, dev_dataset, BATCH_SIZE, vocab, tagset,   \n",
        "                   lr=5e-4, num_epochs=100, eval_every=5)"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FancyTagger(\n",
            "  (embeddings): Embedding(80000, 200)\n",
            "  (lstm): LSTM(200, 256, num_layers=2, bidirectional=True)\n",
            "  (hidden2tag): Linear(in_features=512, out_features=50, bias=True)\n",
            ")\n",
            "['to', 'approve', ':', 'right', 'mouse', 'click', 'on', '\"', 'approved', '\"']\n",
            "['TO', 'VB', ':', 'JJ', 'NN', 'VB', 'IN', '``', 'NN', \"''\"]\n",
            "[   6 4668   47  250 7573 9643   15   10 1414   10    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n",
            "<class 'numpy.ndarray'>\n",
            "['you', 'have', 'received', 'this', 'bbc', 'breaking', 'news', 'alert', 'because', 'you', 'subscribed', 'to', 'it', 'or', ',', 'someone', 'forwarded', 'it', 'to', 'you', '.']\n",
            "['PRP', 'VBP', 'VBN', 'DT', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'PRP', 'VBD', 'IN', 'PRP', 'CC', ',', 'NN', 'VBD', 'PRP', 'IN', 'PRP', '.']\n",
            "[   83    35   498    39  3094  2925   174  3641   115    83 33296     6\n",
            "    22    48     3  1320 19023    22     6    83     4     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "<class 'numpy.ndarray'>\n",
            "**** TRAINING *****\n",
            "Epoch 0 | Loss: 426.7879943847656\n",
            "Epoch 1 | Loss: 109.92282104492188\n",
            "Epoch 2 | Loss: 74.19229888916016\n",
            "Epoch 3 | Loss: 55.357845306396484\n",
            "Epoch 4 | Loss: 42.389217376708984\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.923642871346192\n",
            "**********************\n",
            "Epoch 5 | Loss: 32.3946647644043\n",
            "Epoch 6 | Loss: 24.850383758544922\n",
            "Epoch 7 | Loss: 19.070249557495117\n",
            "Epoch 8 | Loss: 13.998481750488281\n",
            "Epoch 9 | Loss: 10.20982551574707\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9215350964406442\n",
            "**********************\n",
            "Epoch 10 | Loss: 7.521083354949951\n",
            "Epoch 11 | Loss: 5.727670192718506\n",
            "Epoch 12 | Loss: 3.8970253467559814\n",
            "Epoch 13 | Loss: 2.7314889430999756\n",
            "Epoch 14 | Loss: 2.0242819786071777\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9258699542652615\n",
            "**********************\n",
            "Epoch 15 | Loss: 1.5842030048370361\n",
            "Epoch 16 | Loss: 1.2808129787445068\n",
            "Epoch 17 | Loss: 1.1750028133392334\n",
            "Epoch 18 | Loss: 1.0393474102020264\n",
            "Epoch 19 | Loss: 0.9535562992095947\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.927500497116723\n",
            "**********************\n",
            "Epoch 20 | Loss: 0.9162548184394836\n",
            "Epoch 21 | Loss: 0.8977096080780029\n",
            "Epoch 22 | Loss: 0.8771255612373352\n",
            "Epoch 23 | Loss: 0.849116325378418\n",
            "Epoch 24 | Loss: 8.21130657196045\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9199045535891828\n",
            "**********************\n",
            "Epoch 25 | Loss: 4.641456127166748\n",
            "Epoch 26 | Loss: 1.5300959348678589\n",
            "Epoch 27 | Loss: 0.9175665378570557\n",
            "Epoch 28 | Loss: 0.7899332642555237\n",
            "Epoch 29 | Loss: 0.7786052227020264\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9276595744680851\n",
            "**********************\n",
            "Epoch 30 | Loss: 0.7538855075836182\n",
            "Epoch 31 | Loss: 0.7544604539871216\n",
            "Epoch 32 | Loss: 0.7491161227226257\n",
            "Epoch 33 | Loss: 0.7513971328735352\n",
            "Epoch 34 | Loss: 0.751943051815033\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9277391131437661\n",
            "**********************\n",
            "Epoch 35 | Loss: 0.7503928542137146\n",
            "Epoch 36 | Loss: 0.7444468140602112\n",
            "Epoch 37 | Loss: 0.7474665641784668\n",
            "Epoch 38 | Loss: 0.7528023719787598\n",
            "Epoch 39 | Loss: 6.784338474273682\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9232451779677868\n",
            "**********************\n",
            "Epoch 40 | Loss: 3.1049203872680664\n",
            "Epoch 41 | Loss: 1.2324409484863281\n",
            "Epoch 42 | Loss: 0.8528562188148499\n",
            "Epoch 43 | Loss: 0.81582111120224\n",
            "Epoch 44 | Loss: 0.7989320755004883\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9288924239411414\n",
            "**********************\n",
            "Epoch 45 | Loss: 0.7240817546844482\n",
            "Epoch 46 | Loss: 0.8779656887054443\n",
            "Epoch 47 | Loss: 0.7946092486381531\n",
            "Epoch 48 | Loss: 2.196817636489868\n",
            "Epoch 49 | Loss: 2.2118799686431885\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9245575661165242\n",
            "**********************\n",
            "Epoch 50 | Loss: 1.17283296585083\n",
            "Epoch 51 | Loss: 0.8022578954696655\n",
            "Epoch 52 | Loss: 0.7567222118377686\n",
            "Epoch 53 | Loss: 0.6883341670036316\n",
            "Epoch 54 | Loss: 0.6841145753860474\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9270232650626367\n",
            "**********************\n",
            "Epoch 55 | Loss: 0.6866059899330139\n",
            "Epoch 56 | Loss: 0.6890612244606018\n",
            "Epoch 57 | Loss: 0.690585196018219\n",
            "Epoch 58 | Loss: 0.6908935308456421\n",
            "Epoch 59 | Loss: 0.6902788877487183\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9272618810896799\n",
            "**********************\n",
            "Epoch 60 | Loss: 0.6894615292549133\n",
            "Epoch 61 | Loss: 0.6876737475395203\n",
            "Epoch 62 | Loss: 0.6856546401977539\n",
            "Epoch 63 | Loss: 0.6871602535247803\n",
            "Epoch 64 | Loss: 0.7079389095306396\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9269834957247962\n",
            "**********************\n",
            "Epoch 65 | Loss: 3.923560619354248\n",
            "Epoch 66 | Loss: 2.3585917949676514\n",
            "Epoch 67 | Loss: 0.9870017170906067\n",
            "Epoch 68 | Loss: 0.6860406994819641\n",
            "Epoch 69 | Loss: 0.6463374495506287\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9260688009544641\n",
            "**********************\n",
            "Epoch 70 | Loss: 0.6450484395027161\n",
            "Epoch 71 | Loss: 0.646728515625\n",
            "Epoch 72 | Loss: 0.6491975784301758\n",
            "Epoch 73 | Loss: 0.6517190933227539\n",
            "Epoch 74 | Loss: 0.6539033055305481\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9265460330085504\n",
            "**********************\n",
            "Epoch 75 | Loss: 0.6554793119430542\n",
            "Epoch 76 | Loss: 0.6564889550209045\n",
            "Epoch 77 | Loss: 0.6569666266441345\n",
            "Epoch 78 | Loss: 0.656937837600708\n",
            "Epoch 79 | Loss: 0.6564622521400452\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9271823424139988\n",
            "**********************\n",
            "Epoch 80 | Loss: 0.6556664705276489\n",
            "Epoch 81 | Loss: 0.6552080512046814\n",
            "Epoch 82 | Loss: 0.6540348529815674\n",
            "Epoch 83 | Loss: 0.6535511612892151\n",
            "Epoch 84 | Loss: 0.6508837938308716\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9268244183734341\n",
            "**********************\n",
            "Epoch 85 | Loss: 0.651882529258728\n",
            "Epoch 86 | Loss: 4.162554740905762\n",
            "Epoch 87 | Loss: 1.8264914751052856\n",
            "Epoch 88 | Loss: 0.7916130423545837\n",
            "Epoch 89 | Loss: 0.6381507515907288\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9255517995625373\n",
            "**********************\n",
            "Epoch 90 | Loss: 0.6258028745651245\n",
            "Epoch 91 | Loss: 0.6253035664558411\n",
            "Epoch 92 | Loss: 0.6265381574630737\n",
            "Epoch 93 | Loss: 0.628362238407135\n",
            "Epoch 94 | Loss: 0.6302169561386108\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9259494929409425\n",
            "**********************\n",
            "Epoch 95 | Loss: 0.6318951845169067\n",
            "Epoch 96 | Loss: 0.6332510113716125\n",
            "Epoch 97 | Loss: 0.634287416934967\n",
            "Epoch 98 | Loss: 0.6349897384643555\n",
            "Epoch 99 | Loss: 0.6354159116744995\n",
            "**** EVALUATION *****\n",
            "Dev Accuracy: 0.9257904155895804\n",
            "**********************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgLM__WZw4wz",
        "colab_type": "text"
      },
      "source": [
        "### Save Predictions\n",
        "\n",
        "When you are satisfied with your `FancyTagger`'s performance on the dev set, run the cell below to write your predictions on the test set to a text file. \n",
        "\n",
        "You can download `predictions.txt` by going to \n",
        "**View > Table of Contents > Files**\n",
        "\n",
        "Please submit this `predictions.txt` file to Gradescope. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnmj2nSPo1XV",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddSD3-FN9Zzp",
        "colab_type": "code",
        "outputId": "9f020821-be1f-4bea-ffce-2794e13745c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "assert isinstance(model, FancyTagger), 'Please assign your FancyTagger to a variable named model'\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "test_batch_idx, test_batch_lens = test_dataset.get_batches(BATCH_SIZE, vocab, tagset)\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for b in range(len(test_batch_idx)):\n",
        "  logits = model.forward(test_batch_idx[b], test_batch_lens[b])\n",
        "  batch_predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "  batch_size, _ = test_batch_idx[b].shape\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    preds = batch_predictions[i]\n",
        "    \n",
        "    seq_len = int(test_batch_lens[b][i])\n",
        "    for j in range(seq_len):\n",
        "      predictions.append(int(preds[j]))\n",
        "  \n",
        "\n",
        "with open('predictions.txt', 'w') as f:\n",
        "  for p in predictions:\n",
        "    f.write(str(p) + \"\\n\")"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ps', 'i', 'may', 'have', 'to', 'come', 'back', 'to', 'work', 'for', 'a', '615', 'call']\n",
            "[19999    43   109    35     6   328   139     6   163    12     9 41327\n",
            "   582     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWXyhJA3osFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}